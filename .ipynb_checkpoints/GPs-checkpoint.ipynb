{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "762a351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import torch\n",
    "import gpytorch\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from typing import List, Union\n",
    "import os\n",
    "from matplotlib import colormaps\n",
    "import matplotlib as mpl\n",
    "import tqdm\n",
    "from typing import Dict, Any\n",
    "\n",
    "%matplotlib inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"/home/qb/Repos/experiments\")\n",
    "\n",
    "from data import GaussianPreprocessor, SequenceDataset, SequencePredictionDataset, SequenceReconstructionDataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "import pyro\n",
    "from pyro.contrib.timeseries import IndependentMaternGP, LinearlyCoupledMaternGP, DependentMaternGP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "612ebe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_paths = [\"/home/qb/Repos/experiments/Dataset/\"]\n",
    "\n",
    "include_ids = {1: [{\"fn\": \"C1-1001_performance_20220915103555.csv\"}], \n",
    "               2: [{\"fn\": 'C1-1001_performance_20220915151041.csv'}]}\n",
    "\n",
    "# include_ids = {1: [{\"fn\": \"toy_1.csv\"}], \n",
    "#                2: [{\"fn\": 'toy_2.csv'}]}\n",
    "\n",
    "masks = ['steering_percentage', 'fr_pressure', 'chassis_drive_mode', \n",
    "         'pitch', 'position_y', 'yaw_rate', 'real_axe_pressure', 'roll', \n",
    "         'rr_pressure', 'retarder_torque_feedback', 'control_cmd_brake', \n",
    "         'position_z','speed_FL', 'position_x', 'cmd_drive_mode', 'speed_RL', \n",
    "         'test_id', 'steering_target', 'front_axe_pressure', 'retarder_torque', \n",
    "         'imu_vel_forward', 'throttle', 'limited_retarder_torque', 'speed_RR', \n",
    "         'acc_cmd', 'yaw', 'heading', 'rl_pressure', 'imu_sideshift_acceleration', \n",
    "         'throttle_percentage', 'speed_FR', 'fl_pressure', 'driving_mode', 'timestamp']\n",
    "\n",
    "normalized_features = ['engine_rpm', 'imu_forward_acceleration', \"chassis_acc\", \n",
    "                       \"vehicle_speed\", 'drive_motor_torque_nm', 'speed_cmd']\n",
    "\n",
    "onehot_features = ['gear_location_num']\n",
    "\n",
    "filtermasks=[\"driving_mode\"],\n",
    "filtervalues=[[1, 4]],\n",
    "\n",
    "batch_size = 10\n",
    "seq_length = 100\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afcf3431",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/qb/Repos/experiments/Dataset/']\n",
      "1 [{'fn': 'C1-1001_performance_20220915103555.csv'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qb/Repos/experiments/data.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[columns] = x[columns].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([              'engine_rpm',         'brake_percentage',\n",
      "       'imu_forward_acceleration',    'drive_motor_torque_nm',\n",
      "                    'chassis_acc',            'vehicle_speed',\n",
      "                      'speed_cmd',                          0,\n",
      "                                1,                          2,\n",
      "                                3,                          4,\n",
      "                                5,                          6,\n",
      "                                7,                          8,\n",
      "                                9,                         10,\n",
      "                               11,                         12],\n",
      "      dtype='object')\n",
      "2 [{'fn': 'C1-1001_performance_20220915151041.csv'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qb/Repos/experiments/data.py:78: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  x[columns] = x[columns].apply(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index([              'engine_rpm',         'brake_percentage',\n",
      "       'imu_forward_acceleration',    'drive_motor_torque_nm',\n",
      "                    'chassis_acc',            'vehicle_speed',\n",
      "                      'speed_cmd',                          0,\n",
      "                                1,                          2,\n",
      "                                3,                          4,\n",
      "                                5,                          6,\n",
      "                                7,                          8,\n",
      "                                9,                         10,\n",
      "                               11,                         12],\n",
      "      dtype='object')\n",
      "1         engine_rpm  brake_percentage  imu_forward_acceleration  \\\n",
      "0        -0.897032               0.0                  0.037344   \n",
      "1        -0.897032               0.0                  0.037344   \n",
      "2        -0.897032               0.0                  0.037344   \n",
      "3        -0.897032               0.0                  0.037344   \n",
      "4        -0.897032               0.0                  0.037344   \n",
      "...            ...               ...                       ...   \n",
      "258057   -0.895821               0.0                  0.022822   \n",
      "258058   -0.895821               0.0                  0.026971   \n",
      "258059   -0.895821               0.0                  0.026971   \n",
      "258060   -0.895821               0.0                  0.029046   \n",
      "258061   -0.895821               0.0                  0.029046   \n",
      "\n",
      "        drive_motor_torque_nm  chassis_acc  vehicle_speed  speed_cmd  0  1  2  \\\n",
      "0                      -0.875    -0.027778           -1.0       -1.0  0  0  0   \n",
      "1                      -0.875    -0.027778           -1.0       -1.0  0  0  0   \n",
      "2                      -0.875    -0.027778           -1.0       -1.0  0  0  0   \n",
      "3                      -0.875    -0.027778           -1.0       -1.0  0  0  0   \n",
      "4                      -0.875    -0.027778           -1.0       -1.0  0  0  0   \n",
      "...                       ...          ...            ...        ... .. .. ..   \n",
      "258057                 -0.875    -0.027778           -1.0       -1.0  1  0  0   \n",
      "258058                 -0.875    -0.027778           -1.0       -1.0  1  0  0   \n",
      "258059                 -0.875    -0.027778           -1.0       -1.0  1  0  0   \n",
      "258060                 -0.875    -0.027778           -1.0       -1.0  1  0  0   \n",
      "258061                 -0.875    -0.027778           -1.0       -1.0  1  0  0   \n",
      "\n",
      "        3  4  5  6  7  8  9  10  11  12  \n",
      "0       0  0  1  0  0  0  0   0   0   0  \n",
      "1       0  0  1  0  0  0  0   0   0   0  \n",
      "2       0  0  1  0  0  0  0   0   0   0  \n",
      "3       0  0  1  0  0  0  0   0   0   0  \n",
      "4       0  0  1  0  0  0  0   0   0   0  \n",
      "...    .. .. .. .. .. .. ..  ..  ..  ..  \n",
      "258057  0  0  0  0  0  0  0   0   0   0  \n",
      "258058  0  0  0  0  0  0  0   0   0   0  \n",
      "258059  0  0  0  0  0  0  0   0   0   0  \n",
      "258060  0  0  0  0  0  0  0   0   0   0  \n",
      "258061  0  0  0  0  0  0  0   0   0   0  \n",
      "\n",
      "[258062 rows x 20 columns]\n",
      "2         engine_rpm  brake_percentage  imu_forward_acceleration  \\\n",
      "0        -0.440339               0.0                  0.033195   \n",
      "1        -0.441551               0.0                  0.068465   \n",
      "2        -0.440339               0.0                  0.080913   \n",
      "3        -0.440339               0.0                  0.060166   \n",
      "4        -0.441551               0.0                  0.056017   \n",
      "...            ...               ...                       ...   \n",
      "262880   -0.901878              14.0                  0.037344   \n",
      "262881   -0.900666              14.0                  0.037344   \n",
      "262882   -0.900666              14.8                  0.037344   \n",
      "262883   -0.900666              14.8                  0.037344   \n",
      "262884   -0.899455              14.8                  0.037344   \n",
      "\n",
      "        drive_motor_torque_nm  chassis_acc  vehicle_speed  speed_cmd  0  1  2  \\\n",
      "0                   -0.750000    -0.027778       0.105679       -1.0  0  0  0   \n",
      "1                   -0.750000    -0.027778       0.105679       -1.0  0  0  0   \n",
      "2                   -0.750000    -0.027778       0.105679       -1.0  0  0  0   \n",
      "3                   -0.750000    -0.055556       0.105679       -1.0  0  0  0   \n",
      "4                   -0.750000    -0.055556       0.102085       -1.0  0  0  0   \n",
      "...                       ...          ...            ...        ... .. .. ..   \n",
      "262880              -0.833333    -0.027778      -1.000000       -1.0  0  0  0   \n",
      "262881              -0.833333    -0.027778      -1.000000       -1.0  0  0  0   \n",
      "262882              -0.833333    -0.027778      -1.000000       -1.0  0  0  0   \n",
      "262883              -0.833333    -0.027778      -1.000000       -1.0  0  0  0   \n",
      "262884              -0.833333    -0.027778      -1.000000       -1.0  0  0  0   \n",
      "\n",
      "        3  4  5  6  7  8  9  10  11  12  \n",
      "0       0  0  0  0  0  0  0   0   1   0  \n",
      "1       0  0  0  0  0  0  0   0   1   0  \n",
      "2       0  0  0  0  0  0  0   0   1   0  \n",
      "3       0  0  0  0  0  0  0   0   1   0  \n",
      "4       0  0  0  0  0  0  0   0   1   0  \n",
      "...    .. .. .. .. .. .. ..  ..  ..  ..  \n",
      "262880  0  0  1  0  0  0  0   0   0   0  \n",
      "262881  0  0  1  0  0  0  0   0   0   0  \n",
      "262882  0  0  1  0  0  0  0   0   0   0  \n",
      "262883  0  0  1  0  0  0  0   0   0   0  \n",
      "262884  0  0  1  0  0  0  0   0   0   0  \n",
      "\n",
      "[262885 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "preprocessor = GaussianPreprocessor(data_paths, \n",
    "                                    masks=masks, \n",
    "                                    normalized_features=normalized_features, \n",
    "                                    onehot_features=onehot_features)\n",
    "\n",
    "dataset = SequenceReconstructionDataset(data_paths, \n",
    "                                        batch_size=batch_size,\n",
    "                                        seq_length = seq_length,\n",
    "                                        preprocessor=preprocessor, \n",
    "                                        include_ids=include_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8187088e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qb/Repos/experiments/data.py:123: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /opt/conda/conda-bld/pytorch_1666642975993/work/torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  return torch.tensor([seq.to_numpy()])\n"
     ]
    }
   ],
   "source": [
    "obs_dim = dataset.sample().shape[-1]\n",
    "init_learning_rate = 0.1\n",
    "final_learning_rate = 0.001\n",
    "num_steps = 50\n",
    "beta1 = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "71953691",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (1572776797.py, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn [13], line 11\u001b[0;36m\u001b[0m\n\u001b[0;31m    self.\u001b[0m\n\u001b[0m         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class CustomFeatureExtractor(torch.nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_size: int,\n",
    "        hidden_size: Dict[str, Union[int, List[int]]],\n",
    "        output_size: Dict[str, int],\n",
    "        dropout: Dict[str, float],\n",
    "        bidirectional: bool = True,\n",
    "        num_action: int = 0,\n",
    "    ):\n",
    "        super(CustomFeatureExtractor, self).__init__()\n",
    "        self.num_action = num_action\n",
    "\n",
    "        self.lstm_feature_extractor = LSTMFeatureExtractor(\n",
    "            input_size,\n",
    "            hidden_size[\"lstm\"],\n",
    "            output_size[\"lstm\"],\n",
    "            bidirectional=bidirectional,\n",
    "            dropout=dropout[\"lstm\"],\n",
    "        )\n",
    "        if num_action > 0:\n",
    "            self.linear_feature_extractor = MLPFeatureExtractor(\n",
    "                num_action,\n",
    "                hidden_size[\"linear\"],\n",
    "                output_size[\"linear\"],\n",
    "                dropout=dropout[\"linear\"],\n",
    "            )\n",
    "        self.output_layer = torch.nn.tanh(\n",
    "            torch.nn.Linear(\n",
    "                output_size[\"lstm\"] + output_size[\"linear\"], output_size[\"final\"]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def forward(self, seq, a):\n",
    "        x = self.lstm_feature_extractor(seq)\n",
    "        if self.num_action > 0:\n",
    "            x = torch.cat(x, self.linear_feature_extractor(x), axis=1)\n",
    "        return self.output_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2bbecbeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gp = DependentMaternGP(\n",
    "    nu=1.5,\n",
    "    obs_dim=obs_dim,\n",
    "    length_scale_init=1.5 * torch.ones(obs_dim),\n",
    ").double()\n",
    "\n",
    "    # set up optimizer\n",
    "adam = torch.optim.Adam(\n",
    "    gp.parameters(),\n",
    "    lr=init_learning_rate,\n",
    "    betas=(beta1, 0.999),\n",
    "    amsgrad=True,\n",
    ")\n",
    "    # we decay the learning rate over the course of training\n",
    "gamma = (final_learning_rate / init_learning_rate) ** (1.0 / num_steps)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(adam, gamma=gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fac6d676",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m dataset\u001b[38;5;241m.\u001b[39mbatches():\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m batch:\n\u001b[0;32m----> 6\u001b[0m         loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[43mgp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msum() \u001b[38;5;241m/\u001b[39m seq_length\n\u001b[1;32m      7\u001b[0m         loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m      8\u001b[0m         losses\u001b[38;5;241m.\u001b[39mappend(loss\u001b[38;5;241m.\u001b[39mitem())\n",
      "File \u001b[0;32m~/anaconda3/envs/dvkm/lib/python3.9/site-packages/pyro/nn/module.py:677\u001b[0m, in \u001b[0;36mpyro_method.<locals>.cached_fn\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    674\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(fn)\n\u001b[1;32m    675\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcached_fn\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pyro_context:\n\u001b[0;32m--> 677\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dvkm/lib/python3.9/site-packages/pyro/contrib/timeseries/gp.py:516\u001b[0m, in \u001b[0;36mDependentMaternGP.log_prob\u001b[0;34m(self, targets)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;124;03m:param torch.Tensor targets: A 2-dimensional tensor of real-valued targets\u001b[39;00m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;124;03m    of shape ``(T, obs_dim)``, where ``T`` is the length of the time series and ``obs_dim``\u001b[39;00m\n\u001b[1;32m    512\u001b[0m \u001b[38;5;124;03m    is the dimension of the real-valued ``targets`` at each time step\u001b[39;00m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;124;03m:returns torch.Tensor: A (scalar) log probability\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m targets\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m targets\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_dim\n\u001b[0;32m--> 516\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_dist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlog_prob\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtargets\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/dvkm/lib/python3.9/site-packages/pyro/distributions/hmm.py:581\u001b[0m, in \u001b[0;36mGaussianHMM.log_prob\u001b[0;34m(self, value)\u001b[0m\n\u001b[1;32m    578\u001b[0m result \u001b[38;5;241m=\u001b[39m gaussian_tensordot(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init, result, dims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhidden_dim)\n\u001b[1;32m    580\u001b[0m \u001b[38;5;66;03m# Marginalize out final state.\u001b[39;00m\n\u001b[0;32m--> 581\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mresult\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevent_logsumexp\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "File \u001b[0;32m~/anaconda3/envs/dvkm/lib/python3.9/site-packages/pyro/ops/gaussian.py:281\u001b[0m, in \u001b[0;36mGaussian.event_logsumexp\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    279\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim()\n\u001b[1;32m    280\u001b[0m chol_P \u001b[38;5;241m=\u001b[39m safe_cholesky(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprecision)\n\u001b[0;32m--> 281\u001b[0m chol_P_u \u001b[38;5;241m=\u001b[39m \u001b[43mtriangular_solve\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfo_vec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munsqueeze\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchol_P\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\n\u001b[1;32m    283\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    284\u001b[0m u_P_u \u001b[38;5;241m=\u001b[39m chol_P_u\u001b[38;5;241m.\u001b[39mpow(\u001b[38;5;241m2\u001b[39m)\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    285\u001b[0m log_Z: torch\u001b[38;5;241m.\u001b[39mTensor \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog_normalizer\n\u001b[1;32m    287\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m n \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mlog(\u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m math\u001b[38;5;241m.\u001b[39mpi)\n\u001b[1;32m    288\u001b[0m     \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m0.5\u001b[39m \u001b[38;5;241m*\u001b[39m u_P_u\n\u001b[1;32m    289\u001b[0m     \u001b[38;5;241m-\u001b[39m chol_P\u001b[38;5;241m.\u001b[39mdiagonal(dim1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m, dim2\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlog()\u001b[38;5;241m.\u001b[39msum(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    290\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/dvkm/lib/python3.9/site-packages/pyro/ops/tensor_utils.py:445\u001b[0m, in \u001b[0;36mtriangular_solve\u001b[0;34m(x, y, upper, transpose)\u001b[0m\n\u001b[1;32m    443\u001b[0m     y \u001b[38;5;241m=\u001b[39m y\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    444\u001b[0m     upper \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m upper\n\u001b[0;32m--> 445\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msolve_triangular\u001b[49m\u001b[43m(\u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mupper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mupper\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for step in range(num_steps):\n",
    "    adam.zero_grad()\n",
    "    losses = []\n",
    "    for batch in dataset.batches():\n",
    "        for x in batch:\n",
    "            loss = -gp.log_prob(x).sum() / seq_length\n",
    "            loss.backward()\n",
    "            losses.append(loss.item())\n",
    "    adam.step()\n",
    "    scheduler.step()\n",
    "\n",
    "    print(\"[step %03d]  loss: %.3f\" % (step, sum(losses) / batch_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beb4b4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ReadCSV(root: str):\n",
    "    csv_files = []\n",
    "\n",
    "# Iterate directory\n",
    "    for path in os.listdir(root):\n",
    "        # check if current path is a file\n",
    "        if os.path.isfile(os.path.join(root, path)) and path.endswith('.csv'):\n",
    "            csv_files.append(path)\n",
    "            \n",
    "    raw_data = None\n",
    "    \n",
    "    for f in csv_files:\n",
    "        if raw_data is not None:\n",
    "            raw_data = pd.concat([raw_data, pd.read_csv(os.path.join(root, path))], axis=0, ignore_index=True)\n",
    "        else:\n",
    "            raw_data = pd.read_csv(os.path.join(root, path))\n",
    "    \n",
    "    raw_data.reset_index()\n",
    "    return raw_data.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59437fb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "T_multistep = 49\n",
    "T_onestep = 5\n",
    "\n",
    "        # do rolling prediction\n",
    "print(\"doing one-step-ahead forecasting...\")\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "test = dataset.sample().squeeze()\n",
    "\n",
    "print(test.shape)\n",
    "\n",
    "T_onestep = 5\n",
    "\n",
    "\n",
    "onestep_means, onestep_stds = np.zeros((T_onestep, obs_dim)), np.zeros((T_onestep, obs_dim))\n",
    "        \n",
    "for t in range(T_onestep):\n",
    "            # predict one step into the future, conditioning on all previous data.\n",
    "            # note that each call to forecast() conditions on more data than the previous call\n",
    "    dts = torch.tensor([1.0]).double()\n",
    "    pred_dist = gp.forecast(test[0 : T_onestep + t, :], dts)\n",
    "    onestep_means[t, :] = pred_dist.loc.data.numpy()\n",
    "    onestep_stds[t, :] = pred_dist.covariance_matrix.diagonal(dim1=-1, dim2=-2).data.numpy()\n",
    "    \n",
    "    \n",
    "test_y = test[T_onestep:, :]\n",
    "\n",
    "ts = np.linspace(0, test.shape[0] - T_onestep, test.shape[0] - T_onestep);\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "        \n",
    "    f = plt.figure(figsize=(10, 30))\n",
    "    for i in range(5):\n",
    "        ax = f.add_subplot(5, 1, i+1)\n",
    "\n",
    "        # Get upper and lower confidence bounds\n",
    "#         lower, upper = observed_pred.confidence_region()\n",
    "        # Plot training data as black stars\n",
    "        ax.plot(ts, test_y[:, i], 'k*', markersize=2, label='predictions')\n",
    "        # Plot predictive means as blue line\n",
    "        ax.plot(ts, onestep_means[:, i], 'bo', markersize=2, label='observed data')\n",
    "        # Shade between the lower and upper confidence bounds\n",
    "#         ax.plot(overlap_t, overlap_y[:, i], \"rx\", markersize=20, label='overlap between trainset and testset')\n",
    "#         ax.set_title(observ_columns[i])\n",
    "#         ax.fill_between(ts, lowers[:, i], uppers[:, i], alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b92aaf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ecd3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rnn(train_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821f7bdb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dvkm",
   "language": "python",
   "name": "dvkm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
